services:
  spark-master:
    build: .
    container_name: spark-master
    environment:
      - PYSPARK_PYTHON=/usr/bin/python3
      - PYSPARK_DRIVER_PYTHON=/usr/bin/python3
    command: ["/bin/bash", "-c", "/opt/spark/sbin/start-master.sh && tail -f /opt/spark/logs/*"]
    volumes:
      - ../airflow/dags:/opt/airflow/dags
    ports:
      - "8082:8080"   # Dashboard Spark
      - "7077:7077"   # Port pour les workers
    networks:
      - airflow_net

  spark-worker-1:
    build: .
    container_name: spark-worker-1
    environment:
      - PYSPARK_PYTHON=/usr/bin/python3
      - PYSPARK_DRIVER_PYTHON=/usr/bin/python3
    command: ["/bin/bash", "-c", "sleep 5 && /opt/spark/sbin/start-worker.sh spark://spark-master:7077 && tail -f /opt/spark/logs/*"]
    volumes:
      - ../airflow/dags:/opt/airflow/dags
    depends_on:
      - spark-master
    networks:
      - airflow_net

  spark-worker-2:
    build: .
    container_name: spark-worker-2
    environment:
      - PYSPARK_PYTHON=/usr/bin/python3
      - PYSPARK_DRIVER_PYTHON=/usr/bin/python3
    command: ["/bin/bash", "-c", "sleep 5 && /opt/spark/sbin/start-worker.sh spark://spark-master:7077 && tail -f /opt/spark/logs/*"]
    volumes:
      - ../airflow/dags:/opt/airflow/dags
    depends_on:
      - spark-master
    networks:
      - airflow_net

networks:
  airflow_net:
    external: true
    name: postgres_streaming_default
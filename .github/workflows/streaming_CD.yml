name: Streaming CD

on:
  workflow_run:
    workflows: ["Streaming CI"]
    types:
      - completed

jobs:
  continuous_deployement:
    # seulement si Streaming CI est success
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    runs-on: self-hosted
    environment: dev
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Docker
        uses: docker/setup-buildx-action@v2

      # 1. Postgres
      - name: Start Postgres
        run: |
          cd postgres
          docker compose -p postgres_streaming up -d --build

      # 2. Spark
      - name: Start Spark
        run: |
          cd spark
          docker compose -p spark_streaming up -d --build

      # 3. Mailhog
      - name: Start Mailhog
        run: |
          cd mailhog
          docker compose -p mailhog_streaming up -d --build

      # 4. Airflow
      - name: Start Airflow
        run: |
          cd airflow
          
          # Generate a temporary .env file
          $envFile = ".env"
          "AIRFLOW_UID=${{ vars.AIRFLOW_UID }}" | Out-File -FilePath $envFile -Encoding utf8
          "PG_HOST=${{ vars.PG_HOST }}" | Out-File -FilePath $envFile -Append -Encoding utf8
          "PG_PORT=${{ vars.PG_PORT }}" | Out-File -FilePath $envFile -Append -Encoding utf8
          "PG_DBNAME=${{ vars.PG_DBNAME }}" | Out-File -FilePath $envFile -Append -Encoding utf8
          "PG_USER=${{ vars.PG_USER }}" | Out-File -FilePath $envFile -Append -Encoding utf8
          "PG_PASSWORD=${{ secrets.PG_PASSWORD }}" | Out-File -FilePath $envFile -Append -Encoding utf8
          "AIRFLOW_CONN_MY_POSTGRES=postgres://${{ vars.PG_USER }}:${{ secrets.PG_PASSWORD }}@${{ vars.PG_HOST }}:${{ vars.PG_PORT }}/${{ vars.PG_DBNAME }}" | Out-File -FilePath $envFile -Append -Encoding utf8
          "SPARK_HOST=${{ vars.SPARK_HOST }}" | Out-File -FilePath $envFile -Append -Encoding utf8
          "SPARK_PORT=${{ vars.SPARK_PORT }}" | Out-File -FilePath $envFile -Append -Encoding utf8
          "SPARK_PARAM=${{ vars.SPARK_PARAM }}" | Out-File -FilePath $envFile -Append -Encoding utf8
          "AIRFLOW_CONN_MY_SPARK=spark://${{ vars.SPARK_HOST }}:${{ vars.SPARK_PORT }}?${{ vars.SPARK_PARAM }}" | Out-File -FilePath $envFile -Append -Encoding utf8
          "SMTP_USER=${{ secrets.SMTP_USER }}" | Out-File -FilePath $envFile -Append -Encoding utf8
          "SMTP_PASS=${{ secrets.SMTP_PASS }}" | Out-File -FilePath $envFile -Append -Encoding utf8
          "SMTP_SERVER=${{ vars.SMTP_SERVER }}" | Out-File -FilePath $envFile -Append -Encoding utf8
          "SMTP_PORT=${{ vars.SMTP_PORT }}" | Out-File -FilePath $envFile -Append -Encoding utf8
          "RECEIVER=${{ vars.RECEIVER }}" | Out-File -FilePath $envFile -Append -Encoding utf8
          
          docker compose -p airflow_streaming build
          docker compose -p airflow_streaming up -d

      # 5. Ingestion
      - name: Start Ingestion
        run: |
          cd ingestion
          
          # Generate a temporary .env file
          $envFile = ".env"
          "PG_HOST=${{ vars.PG_HOST }}" | Out-File -FilePath $envFile -Encoding utf8
          "PG_PORT=${{ vars.PG_PORT }}" | Out-File -FilePath $envFile -Append -Encoding utf8
          "PG_DBNAME=${{ vars.PG_DBNAME }}" | Out-File -FilePath $envFile -Append -Encoding utf8
          "PG_USER=${{ vars.PG_USER }}" | Out-File -FilePath $envFile -Append -Encoding utf8
          "PG_PASSWORD=${{ secrets.PG_PASSWORD }}" | Out-File -FilePath $envFile -Append -Encoding utf8
          
          docker build -t ingestion_streaming .
          docker run -d --name ingestion_streaming --network postgres_streaming_default --env-file .env ingestion_streaming
